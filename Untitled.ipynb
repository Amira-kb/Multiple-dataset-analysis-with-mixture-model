{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "jx_train=pd.read_csv('jx_train.csv')\n",
    "jx_test=pd.read_csv('jx_test.csv')\n",
    "jaffe=pd.read_csv('jaffe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 676)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaffe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.474509803921569"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=np.array(jx_train)\n",
    "d[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 109 samples, validate on 104 samples\n",
      "Epoch 1/500\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0562 - val_loss: 0.0456\n",
      "Epoch 2/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0222\n",
      "Epoch 3/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0230\n",
      "Epoch 4/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 5/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0198\n",
      "Epoch 6/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0192\n",
      "Epoch 7/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0189\n",
      "Epoch 8/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0190\n",
      "Epoch 9/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0186\n",
      "Epoch 10/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0185\n",
      "Epoch 11/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0182\n",
      "Epoch 12/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0181\n",
      "Epoch 13/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0180\n",
      "Epoch 14/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0179\n",
      "Epoch 15/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0179\n",
      "Epoch 16/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 17/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0177\n",
      "Epoch 18/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0176\n",
      "Epoch 19/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0174\n",
      "Epoch 20/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0170\n",
      "Epoch 21/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0161\n",
      "Epoch 22/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0156\n",
      "Epoch 23/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0180\n",
      "Epoch 24/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0175\n",
      "Epoch 25/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0158\n",
      "Epoch 26/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0154\n",
      "Epoch 27/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 28/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0146\n",
      "Epoch 29/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0143\n",
      "Epoch 30/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0141\n",
      "Epoch 31/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 32/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0138\n",
      "Epoch 33/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0136\n",
      "Epoch 34/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0135\n",
      "Epoch 35/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0138\n",
      "Epoch 36/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0132\n",
      "Epoch 37/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0129\n",
      "Epoch 38/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 39/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 40/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0125\n",
      "Epoch 41/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0122\n",
      "Epoch 42/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 43/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 44/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 45/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 46/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 47/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 48/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 49/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 50/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 51/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 52/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 53/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 54/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 55/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 56/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 57/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 58/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 59/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 60/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 61/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 62/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0093\n",
      "Epoch 63/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 64/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0088\n",
      "Epoch 65/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 66/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 67/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 68/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0089\n",
      "Epoch 69/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0098\n",
      "Epoch 70/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0087\n",
      "Epoch 71/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0092\n",
      "Epoch 72/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0098\n",
      "Epoch 73/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0086\n",
      "Epoch 74/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 75/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 76/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0085\n",
      "Epoch 77/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0084\n",
      "Epoch 78/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 79/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 80/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 82/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 83/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 84/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 85/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 86/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 87/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 88/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 89/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 90/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 91/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 92/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 93/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 94/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 95/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 96/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 97/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 98/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 99/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 100/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 101/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 102/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 103/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 104/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 105/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 106/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 107/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 108/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 109/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Epoch 110/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 111/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 112/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 113/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 114/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 115/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 116/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 117/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 118/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 119/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0065\n",
      "Epoch 120/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 121/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 122/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 123/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 124/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 125/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0067\n",
      "Epoch 126/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 127/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 128/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0066\n",
      "Epoch 129/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 130/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 131/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 132/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 133/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 134/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 135/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0073\n",
      "Epoch 136/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0066\n",
      "Epoch 137/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 138/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0082\n",
      "Epoch 139/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 140/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 141/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 142/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 143/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 144/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0065\n",
      "Epoch 145/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 146/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 147/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0062\n",
      "Epoch 148/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 149/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 150/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 151/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 152/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 153/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 154/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 155/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 156/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 157/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 158/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 159/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 160/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 161/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 162/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 163/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 164/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 165/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 166/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 167/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 168/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 169/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 170/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 171/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 172/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 173/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 174/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 175/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 176/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 177/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 178/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 179/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 180/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 181/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 182/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0058\n",
      "Epoch 183/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 184/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 185/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 186/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 187/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 188/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 189/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 190/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 191/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 192/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 193/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 194/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 195/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 196/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 197/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 198/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 199/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 200/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 201/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 202/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 203/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 204/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 205/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 206/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 207/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 208/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 209/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 210/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 211/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 212/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 213/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 214/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 215/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 216/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 217/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 218/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 219/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 220/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 221/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 222/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 223/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 224/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 225/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 226/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 227/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 228/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 229/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 230/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 231/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0059\n",
      "Epoch 232/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 233/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0066\n",
      "Epoch 234/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 235/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 236/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 237/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0060\n",
      "Epoch 238/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0066\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0066\n",
      "Epoch 240/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0067\n",
      "Epoch 241/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 242/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 243/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 244/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0070\n",
      "Epoch 245/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 246/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 247/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 248/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 249/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 250/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 251/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 252/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0067\n",
      "Epoch 253/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 254/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 255/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 256/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 257/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 258/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 259/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 260/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 261/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 262/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 263/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 264/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 265/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 266/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 267/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 268/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 269/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 270/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 271/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 272/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 273/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 274/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 275/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 276/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 277/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 278/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 279/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 280/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 281/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 282/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 283/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 284/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 285/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 286/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 287/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 288/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 289/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 290/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 291/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 292/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 293/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 294/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 295/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 296/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 297/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 298/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 299/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 300/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 301/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 302/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 303/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 304/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 305/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 306/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 307/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 308/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 309/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 310/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 311/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 312/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 313/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 314/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 315/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 316/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 317/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 318/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 319/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 320/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 321/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 322/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 323/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 324/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 325/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 326/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 327/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 328/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 329/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 330/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 331/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 332/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 333/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 334/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 335/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 336/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 337/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 338/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 339/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 340/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 341/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 342/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 343/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 344/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 345/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 346/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 347/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 348/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 349/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 350/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 351/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 352/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 353/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 354/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 355/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 356/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 357/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 358/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 359/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 360/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 361/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 362/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 363/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 364/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 365/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 366/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 367/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 368/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 369/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 370/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 371/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 372/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 373/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 374/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 375/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 376/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 377/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 378/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 379/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 380/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 381/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 382/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 383/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 384/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 385/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 386/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 387/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 388/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0065\n",
      "Epoch 389/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 390/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 391/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 392/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0065\n",
      "Epoch 393/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0066\n",
      "Epoch 394/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 395/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 396/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 398/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 399/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 400/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 401/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 402/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 403/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 404/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 405/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 406/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 407/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 408/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 409/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 410/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 411/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 412/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 413/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 414/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 415/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 416/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 417/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 418/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 419/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 420/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 421/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 422/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 423/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 424/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 425/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 426/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 427/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 428/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 429/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 430/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 431/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 432/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 433/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 434/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 435/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 436/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 437/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 438/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 439/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 440/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 441/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 442/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 443/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 444/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 445/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 446/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 447/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 448/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 449/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 450/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 451/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 452/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 453/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 454/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 455/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 456/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 457/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 458/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 459/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 460/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 461/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 462/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 463/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 464/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 465/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 466/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 467/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 468/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 469/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 470/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 471/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 472/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 473/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 474/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 475/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 476/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 477/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 478/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 479/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 480/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 481/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 482/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 483/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 484/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 485/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 486/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 487/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 488/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 489/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 490/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 491/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 492/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 493/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 494/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 495/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 496/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 497/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 498/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 499/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 500/500\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "m = keras.models.Sequential()\n",
    "m.add(keras.layers.Dense(1000,  activation='relu', input_shape=(676,)))\n",
    "m.add(keras.layers.Dense(500,  activation='relu'))\n",
    "m.add(keras.layers.Dense(250,  activation='relu'))\n",
    "m.add(keras.layers.Dense(2,    activation='linear', name=\"hidden\"))\n",
    "m.add(keras.layers.Dense(250,  activation='relu'))\n",
    "m.add(keras.layers.Dense(500,  activation='relu'))\n",
    "m.add(keras.layers.Dense(1000,  activation='relu'))\n",
    "m.add(keras.layers.Dense(676,  activation='sigmoid'))\n",
    "m.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam())\n",
    "history = m.fit(jx_train, jx_train, batch_size=32, epochs=500, verbose=1, \n",
    "                validation_data=(jx_test, jx_test))\n",
    "encoder = keras.models.Model(m.input, m.get_layer('hidden').output)\n",
    "Zenc = encoder.predict(jaffe)  # dataset reduit en n=2\n",
    "Renc = m.predict(jx_test)        # reconstruction de l'image a partir de se dataset reduit\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3692487e+02, -4.8848511e+02],\n",
       "       [ 7.9254402e+01, -1.5410681e+02],\n",
       "       [ 2.4627125e+01, -2.4088864e+02],\n",
       "       [ 6.3603329e+01, -2.8266742e+02],\n",
       "       [ 4.1095570e+01, -2.7087506e+02],\n",
       "       [ 2.1312237e+01, -2.6978021e+02],\n",
       "       [-1.4856430e+02, -5.4968219e+02],\n",
       "       [-5.2166737e+01, -3.6961450e+02],\n",
       "       [-7.3002563e+01, -4.2781659e+02],\n",
       "       [ 1.4886850e+02, -5.6285614e+02],\n",
       "       [ 2.7919675e+02, -4.9923544e+02],\n",
       "       [ 8.3621445e+01, -5.6348395e+02],\n",
       "       [ 5.3380718e+01, -6.5549890e+02],\n",
       "       [-1.6169865e+02, -5.9815033e+02],\n",
       "       [ 1.1566183e+02, -1.1354559e+03],\n",
       "       [ 1.1446890e+02, -1.1266084e+03],\n",
       "       [ 5.8214886e+01, -7.4571973e+02],\n",
       "       [ 1.2635853e+02, -8.2987610e+02],\n",
       "       [ 1.2946065e+02, -7.3830280e+02],\n",
       "       [ 9.0148682e+01, -6.8946143e+02],\n",
       "       [ 5.5420502e+02, -3.4619537e+02],\n",
       "       [ 3.4129813e+02, -3.3993176e+02],\n",
       "       [-6.0998425e+01, -4.3484424e+02],\n",
       "       [-1.5155308e+03, -6.0873065e+02],\n",
       "       [-1.3985634e+03, -5.6502429e+02],\n",
       "       [-1.3826154e+03, -4.3115009e+02],\n",
       "       [-1.7018784e+03, -8.2475812e+02],\n",
       "       [-1.6647396e+03, -8.1426422e+02],\n",
       "       [-1.7691879e+03, -9.1955023e+02],\n",
       "       [-1.7676742e+03, -8.9202020e+02],\n",
       "       [-1.5754806e+03, -5.4460101e+02],\n",
       "       [-1.6968912e+03, -7.0983514e+02],\n",
       "       [-2.0357272e+03, -8.1005145e+02],\n",
       "       [-1.5757782e+03, -4.9734088e+02],\n",
       "       [-1.8384691e+03, -6.2057220e+02],\n",
       "       [-1.7293804e+03, -5.6226062e+02],\n",
       "       [-1.8048107e+03, -5.0902069e+02],\n",
       "       [-1.6395343e+03, -4.4509973e+02],\n",
       "       [-1.6368790e+03, -4.3972556e+02],\n",
       "       [-1.6825736e+03, -8.0076971e+02],\n",
       "       [-1.4339525e+03, -6.5918317e+02],\n",
       "       [-1.9309952e+03, -7.9941632e+02],\n",
       "       [-1.3375040e+03, -4.1526553e+02],\n",
       "       [-1.3601661e+03, -4.7175897e+02],\n",
       "       [-1.4723292e+03, -4.0825916e+02],\n",
       "       [ 2.2403661e+02, -2.2143774e+03],\n",
       "       [ 2.0801076e+02, -2.1448635e+03],\n",
       "       [ 1.4896489e+02, -1.9165455e+03],\n",
       "       [ 1.1009797e+03, -1.7589675e+03],\n",
       "       [ 1.0839790e+03, -1.7021550e+03],\n",
       "       [ 9.0025897e+02, -2.0360403e+03],\n",
       "       [ 1.0365355e+03, -1.8027424e+03],\n",
       "       [ 9.4932599e+02, -1.9732106e+03],\n",
       "       [ 3.4012839e+02, -2.0818584e+03],\n",
       "       [ 4.6965958e+02, -2.1493574e+03],\n",
       "       [ 3.8180899e+02, -2.2590679e+03],\n",
       "       [ 5.9909882e+02, -2.1935229e+03],\n",
       "       [ 1.9092969e+02, -2.1320176e+03],\n",
       "       [ 2.6959372e+02, -2.2526680e+03],\n",
       "       [ 2.0019899e+02, -2.1852666e+03],\n",
       "       [ 2.5248772e+02, -2.3290911e+03],\n",
       "       [ 2.3792889e+02, -2.3434968e+03],\n",
       "       [ 1.4404031e+02, -2.1531282e+03],\n",
       "       [ 3.8909753e+02, -2.3172585e+03],\n",
       "       [ 1.2589799e+03, -1.4027911e+03],\n",
       "       [ 1.3256816e+03, -1.3393363e+03],\n",
       "       [ 1.4626050e+03, -1.2440282e+03],\n",
       "       [ 3.3261761e+02, -1.6156021e+02],\n",
       "       [-2.0232860e+02, -4.0509714e+02],\n",
       "       [ 3.4222171e+02, -1.8419743e+02],\n",
       "       [ 5.6909821e+02, -2.0856177e+02],\n",
       "       [ 5.1571405e+02, -2.0021756e+02],\n",
       "       [ 4.5603146e+02, -2.1651309e+02],\n",
       "       [ 8.7744147e+02,  1.0232228e+01],\n",
       "       [ 9.2434113e+02,  5.2194038e+01],\n",
       "       [ 7.2036304e+02, -2.3961563e+02],\n",
       "       [ 7.7368695e+02,  8.2804115e+01],\n",
       "       [ 8.1853204e+02,  4.2666443e+01],\n",
       "       [ 9.2575848e+02,  7.5149094e+01],\n",
       "       [ 8.9201703e+02,  5.1885811e+01],\n",
       "       [ 7.8687817e+02, -3.2674484e+01],\n",
       "       [ 7.6438110e+02, -8.5048599e+01],\n",
       "       [ 8.1114374e+02, -3.8744072e+01],\n",
       "       [ 6.9759760e+02,  9.2368927e+01],\n",
       "       [ 9.7872699e+02,  7.2530182e+01],\n",
       "       [ 9.8687360e+02,  1.0313151e+02],\n",
       "       [ 1.1701038e+03,  7.1547577e+01],\n",
       "       [-5.9608258e+02, -3.1364276e+02],\n",
       "       [-5.8310309e+02, -2.8342719e+02],\n",
       "       [-6.8204547e+02, -3.1916318e+02],\n",
       "       [-2.4729459e+02, -1.3392606e+02],\n",
       "       [-2.2685683e+02, -8.2381348e+01],\n",
       "       [-1.5600597e+02,  5.3754566e+01],\n",
       "       [-6.4191467e+02, -6.0435858e+02],\n",
       "       [-5.5459100e+02, -6.6461902e+02],\n",
       "       [-5.5113458e+02, -1.0954674e+03],\n",
       "       [-3.8336298e+02, -4.6150787e+02],\n",
       "       [-4.4539883e+02, -4.6758728e+02],\n",
       "       [-5.4295038e+02, -6.2669598e+02],\n",
       "       [-7.7311969e+02, -8.9932587e+02],\n",
       "       [-7.4008588e+02, -6.2320416e+02],\n",
       "       [-6.2877643e+02, -6.3395953e+02],\n",
       "       [-8.7927277e+02, -7.1362701e+02],\n",
       "       [-6.8826282e+02, -5.2876068e+02],\n",
       "       [-7.7763751e+02, -5.6544586e+02],\n",
       "       [-4.9339185e+02, -9.9239734e+02],\n",
       "       [-4.3951047e+02, -8.2665851e+02],\n",
       "       [-5.2469617e+02, -8.8036530e+02],\n",
       "       [-1.9123041e+03, -1.7379092e+03],\n",
       "       [-1.9797858e+03, -1.5388971e+03],\n",
       "       [-1.9115704e+03, -1.7226923e+03],\n",
       "       [-1.8024912e+03, -2.1815598e+03],\n",
       "       [-1.7369468e+03, -1.7053973e+03],\n",
       "       [-1.8225419e+03, -1.8644612e+03],\n",
       "       [-1.8427504e+03, -2.1144585e+03],\n",
       "       [-1.7705005e+03, -2.0443748e+03],\n",
       "       [-1.7610289e+03, -2.0334836e+03],\n",
       "       [-9.4864606e+02, -1.3343625e+03],\n",
       "       [-1.0718235e+03, -1.2414839e+03],\n",
       "       [-1.0494495e+03, -1.2587430e+03],\n",
       "       [-1.0791146e+03, -1.2194932e+03],\n",
       "       [-1.0777793e+03, -1.2358352e+03],\n",
       "       [-1.1325114e+03, -1.3136028e+03],\n",
       "       [-2.0121576e+03, -2.2248318e+03],\n",
       "       [-1.2449996e+03, -1.6053369e+03],\n",
       "       [-1.3049064e+03, -1.7623505e+03],\n",
       "       [-1.0821461e+03, -1.4341248e+03],\n",
       "       [-1.2005443e+03, -1.7212336e+03],\n",
       "       [-9.6218542e+02, -1.7034092e+03],\n",
       "       [-6.1521748e+01, -1.1445142e+03],\n",
       "       [-1.4439061e+02, -1.6015710e+03],\n",
       "       [-8.5428452e+01, -1.3020294e+03],\n",
       "       [-2.4661549e+02,  1.7476227e+02],\n",
       "       [-1.0246685e+02,  3.2657483e+02],\n",
       "       [-4.2450076e+02, -1.2224138e+03],\n",
       "       [-5.7248480e+02, -1.5089487e+03],\n",
       "       [-2.4324957e+02, -9.2729449e+02],\n",
       "       [-4.5200745e+02, -1.3880187e+03],\n",
       "       [-4.2020935e+02, -1.2383230e+03],\n",
       "       [-3.8874762e+02, -1.4459868e+03],\n",
       "       [-3.5822513e+02, -1.2006052e+03],\n",
       "       [-4.7856293e+02, -1.5211517e+03],\n",
       "       [-4.7868839e+02, -1.4919668e+03],\n",
       "       [-3.2772388e+02, -1.1080625e+03],\n",
       "       [-3.2052707e+02, -1.1809700e+03],\n",
       "       [-4.6930597e+02, -1.4985012e+03],\n",
       "       [ 2.1719789e+02, -5.9154968e+02],\n",
       "       [ 9.4510201e+01, -7.0668011e+02],\n",
       "       [-2.1616208e+02, -9.6578430e+02],\n",
       "       [-2.1376753e+03,  1.9394230e+03],\n",
       "       [-1.9128278e+03,  2.0101755e+03],\n",
       "       [-2.0305150e+03,  2.0056370e+03],\n",
       "       [-3.7679185e+03,  2.1097278e+03],\n",
       "       [-3.0683059e+03,  1.9288787e+03],\n",
       "       [-3.2769546e+03,  2.1124390e+03],\n",
       "       [-2.5419519e+03,  3.4176520e+02],\n",
       "       [-2.6040667e+03,  3.7154547e+02],\n",
       "       [-2.5697878e+03,  4.1496127e+02],\n",
       "       [-2.6198577e+03,  7.7662610e+02],\n",
       "       [-2.7087390e+03,  9.5214557e+02],\n",
       "       [-2.9112375e+03,  8.6929053e+02],\n",
       "       [-2.9961648e+03,  9.1354095e+02],\n",
       "       [-3.0011682e+03,  9.1320679e+02],\n",
       "       [-2.9745720e+03,  8.8017755e+02],\n",
       "       [-3.2272986e+03,  9.9291058e+02],\n",
       "       [-3.3019985e+03,  9.9857904e+02],\n",
       "       [-3.4150752e+03,  1.0780453e+03],\n",
       "       [-3.8833000e+03,  1.5100543e+03],\n",
       "       [-3.7284128e+03,  1.4487832e+03],\n",
       "       [-3.8386240e+03,  1.6477644e+03],\n",
       "       [-1.5988646e+03, -6.5122841e+01],\n",
       "       [-1.5226678e+03,  5.9548044e+00],\n",
       "       [-1.7431243e+03, -1.4543822e+02],\n",
       "       [-1.3398280e+03,  2.2852114e+01],\n",
       "       [-1.4058153e+03, -4.6674240e-01],\n",
       "       [-9.4294452e+02,  1.1349219e+02],\n",
       "       [-1.5217332e+03, -7.2381760e+01],\n",
       "       [-1.3265703e+03,  8.5878212e+01],\n",
       "       [-1.3078182e+03,  7.3735786e+01],\n",
       "       [-2.0369904e+03, -2.8050764e+01],\n",
       "       [-1.9800775e+03, -1.1111739e+01],\n",
       "       [-2.1255720e+03, -1.2171971e+02],\n",
       "       [-1.9365732e+03, -5.5401512e+01],\n",
       "       [-1.9803361e+03,  1.0016572e+01],\n",
       "       [-2.0157571e+03,  2.7500689e+01],\n",
       "       [-2.0239468e+03, -2.8083698e+02],\n",
       "       [-1.9672130e+03, -2.0235086e+02],\n",
       "       [-1.9930060e+03, -2.1214178e+02],\n",
       "       [-1.8706769e+03, -8.0416555e+00],\n",
       "       [-1.9324249e+03, -8.2342613e+01],\n",
       "       [-1.7969386e+03,  3.6564003e+01],\n",
       "       [ 8.9382507e+02,  1.4071769e+03],\n",
       "       [ 9.6438452e+02,  1.4761541e+03],\n",
       "       [ 8.4300824e+02,  1.4683311e+03],\n",
       "       [ 5.7598446e+01,  1.8968225e+03],\n",
       "       [ 2.4020210e+02,  1.8471765e+03],\n",
       "       [-1.9834404e+02,  1.8364221e+03],\n",
       "       [-5.9820984e+02,  1.9110486e+03],\n",
       "       [-1.6280164e+03,  1.1799075e+03],\n",
       "       [-1.7416376e+03,  8.0710052e+02],\n",
       "       [-1.6525028e+03,  9.1807269e+02],\n",
       "       [-5.6335743e+01,  1.6075458e+03],\n",
       "       [-2.4902869e+02,  1.9466036e+03],\n",
       "       [-3.1237314e+02,  1.8417227e+03],\n",
       "       [-1.0837946e+03,  1.5520999e+03],\n",
       "       [-1.0745569e+03,  1.1280989e+03],\n",
       "       [-1.0266019e+03,  1.3042347e+03],\n",
       "       [-9.3921338e+02,  1.9140713e+03],\n",
       "       [-1.2259943e+03,  2.1394631e+03],\n",
       "       [-1.2014607e+03,  2.1342444e+03],\n",
       "       [-1.2029817e+03,  2.2726780e+03],\n",
       "       [-1.3817491e+03,  2.1784614e+03],\n",
       "       [-1.4339058e+03,  2.3557395e+03]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"auto.csv\", np.array(Zenc), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_train=pd.read_csv('mx_train.csv')\n",
    "mx_test=pd.read_csv('mx_test.csv')\n",
    "mnist=pd.read_csv('mnist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2800 samples, validate on 695 samples\n",
      "Epoch 1/100\n",
      "2800/2800 [==============================] - 6s 2ms/step - loss: 0.1232 - val_loss: 0.0788\n",
      "Epoch 2/100\n",
      "2800/2800 [==============================] - 2s 761us/step - loss: 0.0721 - val_loss: 0.0674\n",
      "Epoch 3/100\n",
      "2800/2800 [==============================] - 2s 766us/step - loss: 0.0659 - val_loss: 0.0640\n",
      "Epoch 4/100\n",
      "2800/2800 [==============================] - 2s 783us/step - loss: 0.0625 - val_loss: 0.0597\n",
      "Epoch 5/100\n",
      "2800/2800 [==============================] - 2s 760us/step - loss: 0.0585 - val_loss: 0.0562\n",
      "Epoch 6/100\n",
      "2800/2800 [==============================] - 2s 779us/step - loss: 0.0560 - val_loss: 0.0548\n",
      "Epoch 7/100\n",
      "2800/2800 [==============================] - 2s 771us/step - loss: 0.0545 - val_loss: 0.0533\n",
      "Epoch 8/100\n",
      "2800/2800 [==============================] - 2s 760us/step - loss: 0.0533 - val_loss: 0.0524\n",
      "Epoch 9/100\n",
      "2800/2800 [==============================] - 2s 761us/step - loss: 0.0523 - val_loss: 0.0517\n",
      "Epoch 10/100\n",
      "2800/2800 [==============================] - 2s 785us/step - loss: 0.0514 - val_loss: 0.0510\n",
      "Epoch 11/100\n",
      "2800/2800 [==============================] - 3s 904us/step - loss: 0.0508 - val_loss: 0.0505\n",
      "Epoch 12/100\n",
      "2800/2800 [==============================] - 2s 758us/step - loss: 0.0503 - val_loss: 0.0501\n",
      "Epoch 13/100\n",
      "2800/2800 [==============================] - 2s 792us/step - loss: 0.0498 - val_loss: 0.0497\n",
      "Epoch 14/100\n",
      "2800/2800 [==============================] - 2s 788us/step - loss: 0.0494 - val_loss: 0.0493\n",
      "Epoch 15/100\n",
      "2800/2800 [==============================] - 2s 805us/step - loss: 0.0488 - val_loss: 0.0489\n",
      "Epoch 16/100\n",
      "2800/2800 [==============================] - 2s 764us/step - loss: 0.0484 - val_loss: 0.0487\n",
      "Epoch 17/100\n",
      "2800/2800 [==============================] - 2s 782us/step - loss: 0.0478 - val_loss: 0.0483\n",
      "Epoch 18/100\n",
      "2800/2800 [==============================] - 2s 822us/step - loss: 0.0473 - val_loss: 0.0479\n",
      "Epoch 19/100\n",
      "2800/2800 [==============================] - 2s 797us/step - loss: 0.0468 - val_loss: 0.0477\n",
      "Epoch 20/100\n",
      "2800/2800 [==============================] - 2s 772us/step - loss: 0.0463 - val_loss: 0.0470\n",
      "Epoch 21/100\n",
      "2800/2800 [==============================] - 2s 819us/step - loss: 0.0458 - val_loss: 0.0468\n",
      "Epoch 22/100\n",
      "2800/2800 [==============================] - 2s 784us/step - loss: 0.0452 - val_loss: 0.0463\n",
      "Epoch 23/100\n",
      "2800/2800 [==============================] - 2s 786us/step - loss: 0.0447 - val_loss: 0.0459\n",
      "Epoch 24/100\n",
      "2800/2800 [==============================] - 2s 856us/step - loss: 0.0440 - val_loss: 0.0457\n",
      "Epoch 25/100\n",
      "2800/2800 [==============================] - 2s 889us/step - loss: 0.0436 - val_loss: 0.0452\n",
      "Epoch 26/100\n",
      "2800/2800 [==============================] - 2s 884us/step - loss: 0.0429 - val_loss: 0.0453\n",
      "Epoch 27/100\n",
      "2800/2800 [==============================] - 2s 777us/step - loss: 0.0424 - val_loss: 0.0448\n",
      "Epoch 28/100\n",
      "2800/2800 [==============================] - 2s 766us/step - loss: 0.0419 - val_loss: 0.0445\n",
      "Epoch 29/100\n",
      "2800/2800 [==============================] - 2s 801us/step - loss: 0.0415 - val_loss: 0.0443\n",
      "Epoch 30/100\n",
      "2800/2800 [==============================] - 2s 803us/step - loss: 0.0413 - val_loss: 0.0447\n",
      "Epoch 31/100\n",
      "2800/2800 [==============================] - 2s 783us/step - loss: 0.0409 - val_loss: 0.0444\n",
      "Epoch 32/100\n",
      "2800/2800 [==============================] - 2s 753us/step - loss: 0.0406 - val_loss: 0.0444\n",
      "Epoch 33/100\n",
      "2800/2800 [==============================] - 2s 784us/step - loss: 0.0406 - val_loss: 0.0447\n",
      "Epoch 34/100\n",
      "2800/2800 [==============================] - 2s 817us/step - loss: 0.0403 - val_loss: 0.0441\n",
      "Epoch 35/100\n",
      "2800/2800 [==============================] - 2s 783us/step - loss: 0.0399 - val_loss: 0.0441\n",
      "Epoch 36/100\n",
      "2800/2800 [==============================] - 2s 762us/step - loss: 0.0396 - val_loss: 0.0440\n",
      "Epoch 37/100\n",
      "2800/2800 [==============================] - 2s 777us/step - loss: 0.0393 - val_loss: 0.0441\n",
      "Epoch 38/100\n",
      "2800/2800 [==============================] - 2s 806us/step - loss: 0.0391 - val_loss: 0.0441\n",
      "Epoch 39/100\n",
      "2800/2800 [==============================] - 2s 801us/step - loss: 0.0390 - val_loss: 0.0437\n",
      "Epoch 40/100\n",
      "2800/2800 [==============================] - 2s 854us/step - loss: 0.0388 - val_loss: 0.0439\n",
      "Epoch 41/100\n",
      "2800/2800 [==============================] - 2s 806us/step - loss: 0.0386 - val_loss: 0.0438\n",
      "Epoch 42/100\n",
      "2800/2800 [==============================] - 2s 814us/step - loss: 0.0384 - val_loss: 0.0440\n",
      "Epoch 43/100\n",
      "2800/2800 [==============================] - 2s 800us/step - loss: 0.0384 - val_loss: 0.0440\n",
      "Epoch 44/100\n",
      "2800/2800 [==============================] - 2s 770us/step - loss: 0.0383 - val_loss: 0.0435\n",
      "Epoch 45/100\n",
      "2800/2800 [==============================] - 2s 799us/step - loss: 0.0381 - val_loss: 0.0438\n",
      "Epoch 46/100\n",
      "2800/2800 [==============================] - 2s 795us/step - loss: 0.0379 - val_loss: 0.0434\n",
      "Epoch 47/100\n",
      "2800/2800 [==============================] - 2s 797us/step - loss: 0.0377 - val_loss: 0.0436\n",
      "Epoch 48/100\n",
      "2800/2800 [==============================] - 2s 767us/step - loss: 0.0376 - val_loss: 0.0439\n",
      "Epoch 49/100\n",
      "2800/2800 [==============================] - 2s 787us/step - loss: 0.0375 - val_loss: 0.0436\n",
      "Epoch 50/100\n",
      "2800/2800 [==============================] - 2s 783us/step - loss: 0.0374 - val_loss: 0.0437\n",
      "Epoch 51/100\n",
      "2800/2800 [==============================] - 2s 755us/step - loss: 0.0373 - val_loss: 0.0437\n",
      "Epoch 52/100\n",
      "2800/2800 [==============================] - 2s 739us/step - loss: 0.0371 - val_loss: 0.0439\n",
      "Epoch 53/100\n",
      "2800/2800 [==============================] - 2s 742us/step - loss: 0.0368 - val_loss: 0.0432\n",
      "Epoch 54/100\n",
      "2800/2800 [==============================] - 2s 773us/step - loss: 0.0366 - val_loss: 0.0435\n",
      "Epoch 55/100\n",
      "2800/2800 [==============================] - 2s 750us/step - loss: 0.0365 - val_loss: 0.0437\n",
      "Epoch 56/100\n",
      "2800/2800 [==============================] - 2s 774us/step - loss: 0.0363 - val_loss: 0.0438\n",
      "Epoch 57/100\n",
      "2800/2800 [==============================] - 2s 792us/step - loss: 0.0363 - val_loss: 0.0438\n",
      "Epoch 58/100\n",
      "2800/2800 [==============================] - 2s 772us/step - loss: 0.0362 - val_loss: 0.0434\n",
      "Epoch 59/100\n",
      "2800/2800 [==============================] - 2s 795us/step - loss: 0.0361 - val_loss: 0.0438\n",
      "Epoch 60/100\n",
      "2800/2800 [==============================] - 2s 814us/step - loss: 0.0359 - val_loss: 0.0434\n",
      "Epoch 61/100\n",
      "2800/2800 [==============================] - 2s 785us/step - loss: 0.0358 - val_loss: 0.0436\n",
      "Epoch 62/100\n",
      "2800/2800 [==============================] - 2s 766us/step - loss: 0.0357 - val_loss: 0.0440\n",
      "Epoch 63/100\n",
      "2800/2800 [==============================] - 2s 810us/step - loss: 0.0356 - val_loss: 0.0438\n",
      "Epoch 64/100\n",
      "2800/2800 [==============================] - 2s 787us/step - loss: 0.0355 - val_loss: 0.0441\n",
      "Epoch 65/100\n",
      "2800/2800 [==============================] - 2s 788us/step - loss: 0.0354 - val_loss: 0.0440\n",
      "Epoch 66/100\n",
      "2800/2800 [==============================] - 2s 762us/step - loss: 0.0353 - val_loss: 0.0438\n",
      "Epoch 67/100\n",
      "2800/2800 [==============================] - 2s 796us/step - loss: 0.0352 - val_loss: 0.0441\n",
      "Epoch 68/100\n",
      "2800/2800 [==============================] - 2s 772us/step - loss: 0.0352 - val_loss: 0.0436\n",
      "Epoch 69/100\n",
      "2800/2800 [==============================] - 2s 785us/step - loss: 0.0350 - val_loss: 0.0437\n",
      "Epoch 70/100\n",
      "2800/2800 [==============================] - 2s 806us/step - loss: 0.0349 - val_loss: 0.0439\n",
      "Epoch 71/100\n",
      "2800/2800 [==============================] - 2s 771us/step - loss: 0.0349 - val_loss: 0.0442\n",
      "Epoch 72/100\n",
      "2800/2800 [==============================] - 2s 783us/step - loss: 0.0347 - val_loss: 0.0440\n",
      "Epoch 73/100\n",
      "2800/2800 [==============================] - 2s 775us/step - loss: 0.0346 - val_loss: 0.0440\n",
      "Epoch 74/100\n",
      "2800/2800 [==============================] - 2s 777us/step - loss: 0.0346 - val_loss: 0.0441\n",
      "Epoch 75/100\n",
      "2800/2800 [==============================] - 2s 785us/step - loss: 0.0344 - val_loss: 0.0441\n",
      "Epoch 76/100\n",
      "2800/2800 [==============================] - 2s 798us/step - loss: 0.0342 - val_loss: 0.0440\n",
      "Epoch 77/100\n",
      "2800/2800 [==============================] - 2s 798us/step - loss: 0.0341 - val_loss: 0.0441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "2800/2800 [==============================] - 2s 788us/step - loss: 0.0339 - val_loss: 0.0442\n",
      "Epoch 79/100\n",
      "2800/2800 [==============================] - 2s 785us/step - loss: 0.0338 - val_loss: 0.0440\n",
      "Epoch 80/100\n",
      "2800/2800 [==============================] - 2s 821us/step - loss: 0.0339 - val_loss: 0.0444\n",
      "Epoch 81/100\n",
      "2800/2800 [==============================] - 2s 778us/step - loss: 0.0339 - val_loss: 0.0445\n",
      "Epoch 82/100\n",
      "2800/2800 [==============================] - 2s 837us/step - loss: 0.0339 - val_loss: 0.0442\n",
      "Epoch 83/100\n",
      "2800/2800 [==============================] - 2s 823us/step - loss: 0.0338 - val_loss: 0.0444\n",
      "Epoch 84/100\n",
      "2800/2800 [==============================] - 2s 810us/step - loss: 0.0337 - val_loss: 0.0445\n",
      "Epoch 85/100\n",
      "2800/2800 [==============================] - 2s 797us/step - loss: 0.0335 - val_loss: 0.0442\n",
      "Epoch 86/100\n",
      "2800/2800 [==============================] - 2s 846us/step - loss: 0.0334 - val_loss: 0.0445\n",
      "Epoch 87/100\n",
      "2800/2800 [==============================] - 2s 817us/step - loss: 0.0333 - val_loss: 0.0444\n",
      "Epoch 88/100\n",
      "2800/2800 [==============================] - 2s 788us/step - loss: 0.0334 - val_loss: 0.0451\n",
      "Epoch 89/100\n",
      "2800/2800 [==============================] - 2s 766us/step - loss: 0.0332 - val_loss: 0.0448\n",
      "Epoch 90/100\n",
      "2800/2800 [==============================] - 2s 798us/step - loss: 0.0330 - val_loss: 0.0445\n",
      "Epoch 91/100\n",
      "2800/2800 [==============================] - 2s 795us/step - loss: 0.0331 - val_loss: 0.0447\n",
      "Epoch 92/100\n",
      "2800/2800 [==============================] - 2s 793us/step - loss: 0.0329 - val_loss: 0.0446\n",
      "Epoch 93/100\n",
      "2800/2800 [==============================] - 2s 757us/step - loss: 0.0327 - val_loss: 0.0448\n",
      "Epoch 94/100\n",
      "2800/2800 [==============================] - 2s 784us/step - loss: 0.0327 - val_loss: 0.0446\n",
      "Epoch 95/100\n",
      "2800/2800 [==============================] - 2s 780us/step - loss: 0.0328 - val_loss: 0.0451\n",
      "Epoch 96/100\n",
      "2800/2800 [==============================] - 2s 773us/step - loss: 0.0330 - val_loss: 0.0451\n",
      "Epoch 97/100\n",
      "2800/2800 [==============================] - 2s 765us/step - loss: 0.0328 - val_loss: 0.0447\n",
      "Epoch 98/100\n",
      "2800/2800 [==============================] - 2s 795us/step - loss: 0.0325 - val_loss: 0.0450\n",
      "Epoch 99/100\n",
      "2800/2800 [==============================] - 2s 861us/step - loss: 0.0325 - val_loss: 0.0443\n",
      "Epoch 100/100\n",
      "2800/2800 [==============================] - 2s 794us/step - loss: 0.0324 - val_loss: 0.0452\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "m2 = keras.models.Sequential()\n",
    "m2.add(keras.layers.Dense(1000,  activation='relu', input_shape=(784,)))\n",
    "m2.add(keras.layers.Dense(500,  activation='relu'))\n",
    "m2.add(keras.layers.Dense(250,  activation='relu'))\n",
    "m2.add(keras.layers.Dense(2,    activation='linear', name=\"hidden\"))\n",
    "m2.add(keras.layers.Dense(250,  activation='relu'))\n",
    "m2.add(keras.layers.Dense(500,  activation='relu'))\n",
    "m2.add(keras.layers.Dense(1000,  activation='relu'))\n",
    "m2.add(keras.layers.Dense(784,  activation='sigmoid'))\n",
    "m2.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam())\n",
    "history2 = m2.fit(mx_train, mx_train, batch_size=128, epochs=100, verbose=1, \n",
    "                validation_data=(mx_test, mx_test))\n",
    "encoder2 = keras.models.Model(m2.input, m2.get_layer('hidden').output)\n",
    "Zenc2 = encoder2.predict(mnist)  # dataset reduit en n=2\n",
    "Renc2 = m2.predict(mnist)        # reconstruction de l'image a partir de se dataset reduit\n",
    "print(history2.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"auto2.csv\", np.array(Zenc2), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfx_train=pd.read_csv('mfx_train.csv')\n",
    "mfx_test=pd.read_csv('mfx_test.csv')\n",
    "mfeat=pd.read_csv('mfeat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 0.2293 - val_loss: 0.1835\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 0s 104us/step - loss: 0.0633 - val_loss: 2.3796e-04\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 0s 100us/step - loss: 2.5335e-04 - val_loss: 2.5281e-04\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 0s 98us/step - loss: 2.5541e-04 - val_loss: 2.5281e-04\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 0s 93us/step - loss: 2.5541e-04 - val_loss: 2.5281e-04\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 0s 96us/step - loss: 2.5541e-04 - val_loss: 2.5281e-04\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 0s 96us/step - loss: 2.5541e-04 - val_loss: 2.5281e-04\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 0s 95us/step - loss: 2.5541e-04 - val_loss: 2.5281e-04\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 0s 95us/step - loss: 2.5541e-04 - val_loss: 2.5281e-04\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 0s 100us/step - loss: 2.5541e-04 - val_loss: 2.5281e-04\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "m3 = keras.models.Sequential()\n",
    "m3.add(keras.layers.Dense(250,  activation='relu', input_shape=(240,)))\n",
    "m3.add(keras.layers.Dense(125,  activation='relu'))\n",
    "m3.add(keras.layers.Dense(62,  activation='relu'))\n",
    "m3.add(keras.layers.Dense(2,    activation='linear', name=\"hidden\"))\n",
    "m3.add(keras.layers.Dense(62,  activation='relu'))\n",
    "m3.add(keras.layers.Dense(125,  activation='relu'))\n",
    "m3.add(keras.layers.Dense(250,  activation='relu'))\n",
    "m3.add(keras.layers.Dense(240,  activation='sigmoid'))\n",
    "m3.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam())\n",
    "history3 = m3.fit(mfx_train, mfx_train, batch_size=128, epochs=10, verbose=1, \n",
    "                validation_data=(mfx_test, mfx_test))\n",
    "encoder3 = keras.models.Model(m3.input, m3.get_layer('hidden').output)\n",
    "Zenc3 = encoder3.predict(mfeat)  # dataset reduit en n=2\n",
    "Renc3 = m3.predict(mfeat)        # reconstruction de l'image a partir de se dataset reduit\n",
    "print(history3.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"auto3.csv\", np.array(Zenc3), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ux_train=pd.read_csv('ux_train.csv')\n",
    "ux_test=pd.read_csv('ux_test.csv')\n",
    "usps=pd.read_csv('usps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8373 samples, validate on 925 samples\n",
      "Epoch 1/10\n",
      "8373/8373 [==============================] - 3s 299us/step - loss: 0.0634 - val_loss: 9.4102e-06\n",
      "Epoch 2/10\n",
      "8373/8373 [==============================] - 2s 186us/step - loss: 9.3961e-06 - val_loss: 9.4102e-06\n",
      "Epoch 3/10\n",
      "8373/8373 [==============================] - 2s 190us/step - loss: 9.3961e-06 - val_loss: 9.4102e-06\n",
      "Epoch 4/10\n",
      "8373/8373 [==============================] - 2s 187us/step - loss: 9.3961e-06 - val_loss: 9.4102e-06\n",
      "Epoch 5/10\n",
      "8373/8373 [==============================] - 2s 196us/step - loss: 9.3961e-06 - val_loss: 9.4102e-06\n",
      "Epoch 6/10\n",
      "8373/8373 [==============================] - 2s 185us/step - loss: 9.3961e-06 - val_loss: 9.4102e-06\n",
      "Epoch 7/10\n",
      "8373/8373 [==============================] - 2s 195us/step - loss: 9.3961e-06 - val_loss: 9.4102e-06\n",
      "Epoch 8/10\n",
      "8373/8373 [==============================] - 2s 183us/step - loss: 9.3961e-06 - val_loss: 9.4102e-06\n",
      "Epoch 9/10\n",
      "8373/8373 [==============================] - 2s 193us/step - loss: 9.3961e-06 - val_loss: 9.4102e-06\n",
      "Epoch 10/10\n",
      "8373/8373 [==============================] - 2s 187us/step - loss: 9.3961e-06 - val_loss: 9.4102e-06\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "m4 = keras.models.Sequential()\n",
    "m4.add(keras.layers.Dense(500,  activation='relu', input_shape=(256,)))\n",
    "m4.add(keras.layers.Dense(250,  activation='relu'))\n",
    "m4.add(keras.layers.Dense(125,  activation='relu'))\n",
    "m4.add(keras.layers.Dense(2,    activation='linear',input_shape=(256,), name=\"hidden\"))\n",
    "m4.add(keras.layers.Dense(125,  activation='relu'))\n",
    "m4.add(keras.layers.Dense(250,  activation='relu'))\n",
    "m4.add(keras.layers.Dense(500,  activation='relu'))\n",
    "m4.add(keras.layers.Dense(256,  activation='sigmoid'))\n",
    "m4.compile(loss='mse', optimizer = keras.optimizers.Adam())\n",
    "history4 = m4.fit(ux_train, ux_train, batch_size=128, epochs=10, verbose=1, \n",
    "                validation_data=(ux_test, ux_test))\n",
    "encoder4 = keras.models.Model(m4.input, m4.get_layer('hidden').output)\n",
    "Zenc4 = encoder4.predict(usps)  # dataset reduit en n=2\n",
    "Renc4 = m4.predict(usps)        # reconstruction de l'image a partir de se dataset reduit\n",
    "print(history4.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"auto4.csv\", np.array(Zenc4), delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
